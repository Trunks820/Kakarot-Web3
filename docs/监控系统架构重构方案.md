# 监控系统架构重构方案

> **文档版本**: v1.0  
> **创建日期**: 2025-11-07  
> **状态**: 📝 设计阶段

---

## 📋 目录

1. [当前问题分析](#当前问题分析)
2. [新架构设计](#新架构设计)
3. [表结构对比](#表结构对比)
4. [零停机迁移方案](#零停机迁移方案)
5. [实施步骤](#实施步骤)
6. [风险评估](#风险评估)
7. [回滚方案](#回滚方案)

---

## 🔍 当前问题分析

### 现有表结构

```
quick_monitor_template (配置表)
├── id
├── source_type (smart/batch)
├── chain_type (sol/bsc)
├── min_market_cap (仅smart使用)
├── time_interval
├── top_holders_threshold
├── events_config
├── trigger_logic
├── notify_methods
└── status

sol_ws_batch_pool (批次+Token混合表)
├── id
├── source_type (smart/batch)
├── chain_type
├── batch_id
├── ca (Token地址)
├── token_name
├── token_symbol
├── market_cap
├── template_id → quick_monitor_template.id
└── is_active
```

### 核心问题

#### 1. **数据冗余严重**
```
批次1: 99个Token → 99条记录都存 template_id=10
批次2: 99个Token → 99条记录都存 template_id=10
...
数据量 2000 条，实际上可能只有 20-30 个不同的配置
```

#### 2. **概念混淆**
- `sol_ws_batch_pool` 既存批次信息，又存Token明细
- 查询批次列表需要 `GROUP BY`，容易出现重复
- 批次配置分散在多条Token记录中

#### 3. **查询复杂**
```sql
-- 查询批次列表需要复杂的GROUP BY和JOIN
SELECT 
  p.batch_id,
  min(t.config_name) as configName,
  count(*) as tokenCount
FROM sol_ws_batch_pool p
LEFT JOIN quick_monitor_template t ON p.template_id = t.id
GROUP BY p.batch_id, p.source_type, p.chain_type;
```

#### 4. **扩展性差**
- 新增监控类型（如区块监控）需要新建表
- 配置无法在不同监控类型间复用
- 批次管理和Token管理耦合

---

## 🎯 新架构设计

### 设计理念：三层分离

```
┌─────────────────────────────────────────────────────────┐
│  1. 配置层 (Configuration)                               │
│     monitor_config                                      │
│     - 存储监控规则配置                                   │
│     - 可被多个任务复用                                   │
│     - 与具体监控目标无关                                 │
└─────────────────────────────────────────────────────────┘
                           ↓ 引用
┌─────────────────────────────────────────────────────────┐
│  2. 任务层 (Task)                                        │
│     monitor_task                                        │
│     - 定义监控任务（配置 + 目标来源）                    │
│     - 智能任务：配置 + 市值区间                         │
│     - 批量任务：配置 + CA列表                           │
│     - 区块任务：配置（全局监控）                        │
└─────────────────────────────────────────────────────────┘
                           ↓ 分配
┌─────────────────────────────────────────────────────────┐
│  3. 执行层 (Execution)                                   │
│     ws_batch_execution                                  │
│     - WS连接技术实现                                     │
│     - 每批最多99个CA                                     │
│     - Python监控进程读取                                 │
└─────────────────────────────────────────────────────────┘
                           ↓ 产生
┌─────────────────────────────────────────────────────────┐
│  4. 告警层 (Alert)                                       │
│     monitor_alert_log                                   │
│     - 统一的告警日志                                     │
│     - 所有类型监控的告警都记录在这里                     │
└─────────────────────────────────────────────────────────┘
```

---

## 📊 表结构对比

### 新表结构

#### 1. **monitor_config** (监控配置表)

```sql
CREATE TABLE monitor_config (
  id BIGINT PRIMARY KEY AUTO_INCREMENT COMMENT '配置ID',
  config_name VARCHAR(100) NOT NULL COMMENT '配置名称',
  config_type VARCHAR(20) DEFAULT 'general' COMMENT '配置类型：general/smart/batch/block',
  chain_type VARCHAR(10) NOT NULL COMMENT '链类型：sol/bsc',
  
  -- 监控配置
  time_interval VARCHAR(10) COMMENT '时间间隔：5m/15m/1h/4h',
  top_holders_threshold DECIMAL(5,2) COMMENT '前N持有者阈值',
  events_config TEXT COMMENT '事件配置(JSON): {priceChange, holders, volume}',
  trigger_logic VARCHAR(10) DEFAULT 'any' COMMENT '触发逻辑：any/all',
  notify_methods VARCHAR(100) COMMENT '通知方式：telegram,wechat',
  
  -- 元数据
  description TEXT COMMENT '配置描述',
  status TINYINT DEFAULT 1 COMMENT '状态：1启用/0停用',
  create_by VARCHAR(64) COMMENT '创建者',
  create_time DATETIME DEFAULT CURRENT_TIMESTAMP COMMENT '创建时间',
  update_by VARCHAR(64) COMMENT '更新者',
  update_time DATETIME DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP COMMENT '更新时间',
  del_flag TINYINT DEFAULT 0 COMMENT '删除标志：0未删除/1已删除',
  
  KEY idx_chain_type (chain_type),
  KEY idx_status (status)
) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COMMENT='监控配置表';
```

#### 2. **monitor_task** (监控任务表)

```sql
CREATE TABLE monitor_task (
  id BIGINT PRIMARY KEY AUTO_INCREMENT COMMENT '任务ID',
  task_name VARCHAR(100) NOT NULL COMMENT '任务名称',
  task_type VARCHAR(20) NOT NULL COMMENT '任务类型：smart/batch/block',
  config_id BIGINT NOT NULL COMMENT '关联配置ID',
  chain_type VARCHAR(10) NOT NULL COMMENT '链类型：sol/bsc',
  
  -- 智能监控专用字段
  min_market_cap DECIMAL(20,2) COMMENT '最小市值(仅smart)',
  max_market_cap DECIMAL(20,2) COMMENT '最大市值(仅smart)',
  has_twitter TINYINT COMMENT '是否有Twitter(仅smart)',
  
  -- 批量监控专用字段
  ca_count INT DEFAULT 0 COMMENT 'Token数量(仅batch)',
  
  -- 执行状态
  status TINYINT DEFAULT 1 COMMENT '状态：1启用/0停用',
  last_run_time DATETIME COMMENT '最后执行时间',
  next_run_time DATETIME COMMENT '下次执行时间',
  
  -- 元数据
  create_by VARCHAR(64) COMMENT '创建者',
  create_time DATETIME DEFAULT CURRENT_TIMESTAMP COMMENT '创建时间',
  update_time DATETIME DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP COMMENT '更新时间',
  
  FOREIGN KEY (config_id) REFERENCES monitor_config(id),
  KEY idx_task_type (task_type),
  KEY idx_chain_type (chain_type),
  KEY idx_status (status)
) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COMMENT='监控任务表';
```

#### 3. **ws_batch_execution** (WS批次执行表)

```sql
CREATE TABLE ws_batch_execution (
  id BIGINT PRIMARY KEY AUTO_INCREMENT COMMENT '记录ID',
  task_id BIGINT NOT NULL COMMENT '关联任务ID',
  task_type VARCHAR(20) NOT NULL COMMENT '任务类型(冗余)',
  batch_id INT NOT NULL COMMENT '批次编号',
  chain_type VARCHAR(10) NOT NULL COMMENT '链类型',
  
  -- Token信息
  ca VARCHAR(255) NOT NULL COMMENT 'Token合约地址',
  token_name VARCHAR(100) COMMENT 'Token名称',
  token_symbol VARCHAR(50) COMMENT 'Token符号',
  pair_address VARCHAR(255) COMMENT '交易对地址',
  market_cap DECIMAL(20,2) COMMENT '市值',
  twitter_url VARCHAR(255) COMMENT 'Twitter链接',
  
  -- 执行状态
  priority INT DEFAULT 0 COMMENT '优先级',
  sort_order INT DEFAULT 0 COMMENT '排序',
  is_active TINYINT DEFAULT 1 COMMENT '状态：1启用/0停用',
  
  -- 元数据
  create_time DATETIME DEFAULT CURRENT_TIMESTAMP COMMENT '创建时间',
  update_time DATETIME DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP COMMENT '更新时间',
  
  FOREIGN KEY (task_id) REFERENCES monitor_task(id) ON DELETE CASCADE,
  UNIQUE KEY uk_task_ca (task_id, ca),
  KEY idx_batch (task_id, batch_id),
  KEY idx_chain_type (chain_type),
  KEY idx_active (is_active)
) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COMMENT='WS批次执行表';
```

#### 4. **monitor_alert_log** (监控告警日志表)

```sql
CREATE TABLE monitor_alert_log (
  id BIGINT PRIMARY KEY AUTO_INCREMENT COMMENT '告警ID',
  task_id BIGINT NOT NULL COMMENT '关联任务ID',
  task_type VARCHAR(20) NOT NULL COMMENT '任务类型',
  chain_type VARCHAR(10) NOT NULL COMMENT '链类型',
  
  -- Token信息
  ca VARCHAR(255) COMMENT 'Token地址(如果是Token监控)',
  token_name VARCHAR(100) COMMENT 'Token名称',
  token_symbol VARCHAR(50) COMMENT 'Token符号',
  
  -- 告警详情
  alert_type VARCHAR(50) NOT NULL COMMENT '告警类型：price_change/holder_change/volume_change',
  alert_title VARCHAR(200) COMMENT '告警标题',
  alert_content TEXT COMMENT '告警内容(JSON)',
  
  -- 通知状态
  notify_status VARCHAR(20) DEFAULT 'pending' COMMENT '通知状态：pending/sent/failed',
  notify_methods VARCHAR(100) COMMENT '通知方式',
  notify_time DATETIME COMMENT '通知时间',
  
  -- 元数据
  create_time DATETIME DEFAULT CURRENT_TIMESTAMP COMMENT '创建时间',
  
  FOREIGN KEY (task_id) REFERENCES monitor_task(id),
  KEY idx_task (task_id),
  KEY idx_chain_type (chain_type),
  KEY idx_alert_type (alert_type),
  KEY idx_create_time (create_time)
) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COMMENT='监控告警日志表';
```

### 数据量对比

| 表名 | 旧架构 | 新架构 | 说明 |
|------|--------|--------|------|
| 配置 | 2000条(冗余) | ~30条 | 配置独立存储 |
| 批次元信息 | 无 | ~30条 | 批次作为独立实体 |
| Token明细 | 2000条 | 2000条 | 不变 |
| 告警日志 | 分散多表 | 统一存储 | 查询更方便 |

---

## 🔄 零停机迁移方案

### 阶段1：准备阶段（1天）

#### 1.1 创建新表
```sql
-- 执行新表创建SQL
-- 所有新表都带 _new 后缀，避免冲突
CREATE TABLE monitor_config_new (...);
CREATE TABLE monitor_task_new (...);
CREATE TABLE ws_batch_execution_new (...);
CREATE TABLE monitor_alert_log_new (...);
```

#### 1.2 数据分析
```sql
-- 分析现有配置，提取唯一配置
SELECT DISTINCT 
  time_interval,
  top_holders_threshold,
  events_config,
  trigger_logic,
  notify_methods,
  COUNT(*) as token_count
FROM sol_ws_batch_pool p
JOIN quick_monitor_template t ON p.template_id = t.id
GROUP BY time_interval, top_holders_threshold, events_config, trigger_logic, notify_methods;
```

### 阶段2：数据迁移（2-3天）

#### 2.1 迁移配置 (quick_monitor_template → monitor_config_new)

```sql
-- 迁移配置数据
INSERT INTO monitor_config_new (
  config_name,
  config_type,
  chain_type,
  time_interval,
  top_holders_threshold,
  events_config,
  trigger_logic,
  notify_methods,
  status,
  create_time
)
SELECT 
  config_name,
  source_type as config_type,
  chain_type,
  time_interval,
  top_holders_threshold,
  events_config,
  trigger_logic,
  notify_methods,
  status,
  create_time
FROM quick_monitor_template
WHERE del_flag = 0;

-- 记录旧ID到新ID的映射
CREATE TEMPORARY TABLE config_id_mapping (
  old_id BIGINT,
  new_id BIGINT
);
```

#### 2.2 迁移任务 (按批次提取 → monitor_task_new)

```sql
-- 智能监控任务迁移
INSERT INTO monitor_task_new (
  task_name,
  task_type,
  config_id,
  chain_type,
  min_market_cap,
  max_market_cap,
  status,
  create_time
)
SELECT 
  CONCAT(t.config_name, ' - ', p.batch_id) as task_name,
  'smart' as task_type,
  m.new_id as config_id,
  p.chain_type,
  t.min_market_cap,
  NULL as max_market_cap,
  MAX(p.is_active) as status,
  MIN(p.create_time) as create_time
FROM sol_ws_batch_pool p
JOIN quick_monitor_template t ON p.template_id = t.id
JOIN config_id_mapping m ON t.id = m.old_id
WHERE p.source_type = 'smart'
GROUP BY p.batch_id, p.source_type, p.chain_type, p.template_id;

-- 批量监控任务迁移
INSERT INTO monitor_task_new (
  task_name,
  task_type,
  config_id,
  chain_type,
  ca_count,
  status,
  create_time
)
SELECT 
  CONCAT(t.config_name, ' - ', p.batch_id) as task_name,
  'batch' as task_type,
  m.new_id as config_id,
  p.chain_type,
  COUNT(*) as ca_count,
  MAX(p.is_active) as status,
  MIN(p.create_time) as create_time
FROM sol_ws_batch_pool p
JOIN quick_monitor_template t ON p.template_id = t.id
JOIN config_id_mapping m ON t.id = m.old_id
WHERE p.source_type = 'batch'
GROUP BY p.batch_id, p.source_type, p.chain_type, p.template_id;
```

#### 2.3 迁移Token明细 (sol_ws_batch_pool → ws_batch_execution_new)

```sql
-- 迁移Token明细
INSERT INTO ws_batch_execution_new (
  task_id,
  task_type,
  batch_id,
  chain_type,
  ca,
  token_name,
  token_symbol,
  pair_address,
  market_cap,
  priority,
  sort_order,
  is_active,
  create_time
)
SELECT 
  task.id as task_id,
  p.source_type as task_type,
  p.batch_id,
  p.chain_type,
  p.ca,
  p.token_name,
  p.token_symbol,
  p.pair_address,
  p.market_cap,
  p.priority,
  p.sort_order,
  p.is_active,
  p.create_time
FROM sol_ws_batch_pool p
JOIN monitor_task_new task ON (
  task.chain_type = p.chain_type 
  AND task.task_name LIKE CONCAT('% - ', p.batch_id)
);
```

#### 2.4 数据校验

```sql
-- 校验记录数
SELECT 'monitor_config' as table_name, COUNT(*) as count FROM monitor_config_new
UNION ALL
SELECT 'monitor_task', COUNT(*) FROM monitor_task_new
UNION ALL
SELECT 'ws_batch_execution', COUNT(*) FROM ws_batch_execution_new;

-- 校验批次Token数量
SELECT 
  task_id,
  batch_id,
  COUNT(*) as token_count
FROM ws_batch_execution_new
GROUP BY task_id, batch_id
HAVING token_count > 99;  -- 检查是否有超过99个的批次
```

### 阶段3：双写过渡（1周）

#### 3.1 修改Java后端代码

```java
// BatchMonitorServiceImpl.java
@Service
public class BatchMonitorServiceImpl implements IBatchMonitorService {
    
    @Autowired
    private MonitorConfigMapper configMapper;  // 新Mapper
    
    @Autowired
    private MonitorTaskMapper taskMapper;      // 新Mapper
    
    @Autowired
    private WsBatchExecutionMapper executionMapper;  // 新Mapper
    
    // 双写模式
    private boolean DUAL_WRITE_MODE = true;  // 配置开关
    
    @Override
    public Map<String, Object> smartBatchAdd(List<String> addresses, Map<String, Object> config) {
        // 1. 写入新表
        Long taskId = saveToNewTables(addresses, config);
        
        // 2. 如果开启双写，同时写入旧表（兼容Python）
        if (DUAL_WRITE_MODE) {
            saveToOldTables(addresses, config);
        }
        
        return result;
    }
}
```

#### 3.2 修改Python监控脚本

```python
# monitor_service.py
class MonitorService:
    def __init__(self):
        self.use_new_schema = os.getenv('USE_NEW_SCHEMA', 'false') == 'true'
    
    def load_monitoring_tasks(self):
        if self.use_new_schema:
            return self._load_from_new_tables()
        else:
            return self._load_from_old_tables()
    
    def _load_from_new_tables(self):
        """从新表结构加载任务"""
        query = """
        SELECT 
          t.id as task_id,
          t.task_type,
          t.chain_type,
          c.time_interval,
          c.events_config,
          c.trigger_logic,
          c.notify_methods,
          e.batch_id,
          e.ca,
          e.token_name
        FROM monitor_task t
        JOIN monitor_config c ON t.config_id = c.id
        JOIN ws_batch_execution e ON t.id = e.task_id
        WHERE t.status = 1 AND e.is_active = 1
        """
        return self.db.execute(query)
    
    def _load_from_old_tables(self):
        """从旧表结构加载任务（兼容）"""
        query = """
        SELECT 
          p.batch_id,
          p.chain_type,
          p.ca,
          t.time_interval,
          t.events_config,
          t.trigger_logic,
          t.notify_methods
        FROM sol_ws_batch_pool p
        JOIN quick_monitor_template t ON p.template_id = t.id
        WHERE p.is_active = 1
        """
        return self.db.execute(query)
```

### 阶段4：切换验证（3-5天）

#### 4.1 灰度切换

**第1天：10%流量**
```properties
# application.properties
monitor.use.new.schema=false
monitor.dual.write=true

# Python环境变量
USE_NEW_SCHEMA=false
```

**第2天：50%流量**
```properties
# 部分Python实例切换到新表
USE_NEW_SCHEMA=true  # 50%实例
USE_NEW_SCHEMA=false # 50%实例
```

**第3天：100%流量**
```properties
# 全部切换到新表
monitor.use.new.schema=true
USE_NEW_SCHEMA=true
```

#### 4.2 监控指标

```sql
-- 每小时执行，对比新旧表数据
SELECT 
  'old_active_batches' as metric,
  COUNT(DISTINCT CONCAT(batch_id, '_', chain_type)) as value
FROM sol_ws_batch_pool
WHERE is_active = 1

UNION ALL

SELECT 
  'new_active_tasks' as metric,
  COUNT(*) as value
FROM monitor_task_new
WHERE status = 1;

-- 告警数量对比
SELECT 
  DATE(create_time) as date,
  'old' as source,
  COUNT(*) as alert_count
FROM token_monitor_alert_log
WHERE create_time >= DATE_SUB(NOW(), INTERVAL 7 DAY)
GROUP BY DATE(create_time)

UNION ALL

SELECT 
  DATE(create_time) as date,
  'new' as source,
  COUNT(*) as alert_count
FROM monitor_alert_log_new
WHERE create_time >= DATE_SUB(NOW(), INTERVAL 7 DAY)
GROUP BY DATE(create_time);
```

### 阶段5：完成迁移（1天）

#### 5.1 重命名表

```sql
-- 备份旧表
RENAME TABLE quick_monitor_template TO quick_monitor_template_backup;
RENAME TABLE sol_ws_batch_pool TO sol_ws_batch_pool_backup;

-- 新表去掉 _new 后缀
RENAME TABLE monitor_config_new TO monitor_config;
RENAME TABLE monitor_task_new TO monitor_task;
RENAME TABLE ws_batch_execution_new TO ws_batch_execution;
RENAME TABLE monitor_alert_log_new TO monitor_alert_log;
```

#### 5.2 清理代码

```java
// 移除双写逻辑
private boolean DUAL_WRITE_MODE = false;  // 关闭

// 删除旧Mapper引用
// @Autowired
// private SolWsBatchPoolMapper oldMapper;  // 删除
```

```python
# 移除旧表逻辑
def load_monitoring_tasks(self):
    return self._load_from_new_tables()  # 只保留新逻辑
```

#### 5.3 观察期（1周）

- 监控告警数量是否正常
- 监控任务执行是否正常
- 用户反馈是否有异常
- 性能指标是否改善

#### 5.4 删除旧表（1个月后）

```sql
-- 确认无问题后，删除备份表
DROP TABLE IF EXISTS quick_monitor_template_backup;
DROP TABLE IF EXISTS sol_ws_batch_pool_backup;
DROP TABLE IF EXISTS token_monitor_alert_log;  -- 如果有的话
```

---

## 📅 实施步骤时间表

| 阶段 | 工作内容 | 预计时间 | 责任人 | 风险等级 |
|------|---------|----------|--------|----------|
| **准备** | 创建新表、数据分析 | 1天 | Backend | 低 |
| **迁移** | 数据迁移、校验 | 2-3天 | Backend | 中 |
| **双写** | 代码改造、测试 | 1周 | Backend + Python | 中 |
| **切换** | 灰度切换、监控 | 3-5天 | Backend + Python + 运维 | 高 |
| **完成** | 重命名表、清理代码 | 1天 | Backend | 低 |
| **观察** | 监控数据、用户反馈 | 1周 | 全员 | 中 |
| **清理** | 删除旧表 | 1天 | DBA | 低 |

**总计：约 2-3 周完成迁移**

---

## ⚠️ 风险评估

### 高风险项

| 风险 | 影响 | 概率 | 缓解措施 |
|------|------|------|----------|
| 数据迁移错误 | 监控失效 | 中 | 双写+校验+灰度 |
| Python脚本兼容性 | 监控中断 | 高 | 保留旧表读取逻辑 |
| 性能下降 | 系统卡顿 | 低 | 提前压测+索引优化 |
| 告警遗漏 | 用户投诉 | 中 | 双写期对比告警数 |

### 中风险项

| 风险 | 影响 | 概率 | 缓解措施 |
|------|------|------|----------|
| 批次ID冲突 | 数据混乱 | 低 | 迁移时重新分配ID |
| 配置丢失 | 部分功能失效 | 低 | 迁移前导出配置备份 |
| Redis缓存不一致 | 数据不同步 | 中 | 切换时清空Redis |

### 低风险项

- 前端显示异常（影响小，可快速修复）
- 文档不同步（不影响功能）
- 旧API调用失败（已废弃API）

---

## 🔙 回滚方案

### 场景1：数据迁移阶段发现问题

**操作：**
```sql
-- 直接删除新表重新迁移
DROP TABLE monitor_config_new;
DROP TABLE monitor_task_new;
DROP TABLE ws_batch_execution_new;
DROP TABLE monitor_alert_log_new;
```

**影响：** 无，旧表未动

### 场景2：双写阶段发现问题

**操作：**
```properties
# 关闭双写，只写旧表
monitor.dual.write=false
```

**影响：** 新表数据可能不完整，但不影响现有功能

### 场景3：切换后发现严重问题

**操作：**
```properties
# 紧急回滚到旧表
monitor.use.new.schema=false
USE_NEW_SCHEMA=false

# Python重启所有实例
systemctl restart monitor-service
```

```sql
-- 如果新表数据有问题，从备份表恢复
DROP TABLE monitor_config;
DROP TABLE monitor_task;
DROP TABLE ws_batch_execution;

RENAME TABLE quick_monitor_template_backup TO quick_monitor_template;
RENAME TABLE sol_ws_batch_pool_backup TO sol_ws_batch_pool;
```

**影响：** 切换期间产生的新数据可能丢失，需要手动补录

### 场景4：部分功能异常

**操作：**
```properties
# 针对特定功能回滚
monitor.smart.use.new.schema=false  # 智能监控用旧表
monitor.batch.use.new.schema=true   # 批量监控用新表
```

**影响：** 部分功能使用旧逻辑，增加维护成本

---

## 📈 预期收益

### 技术收益

| 指标 | 当前 | 优化后 | 提升 |
|------|------|--------|------|
| 配置查询速度 | ~200ms | ~10ms | **95%↑** |
| 批次列表查询 | ~500ms (GROUP BY) | ~50ms (直接查询) | **90%↑** |
| 数据冗余率 | ~98% | ~2% | **96%↓** |
| 代码复杂度 | 高 (多表JOIN) | 低 (简单关联) | **明显降低** |

### 业务收益

- ✅ **配置复用**：创建一次配置，多个任务共享
- ✅ **扩展性强**：新增监控类型只需加 task_type
- ✅ **维护简单**：表结构清晰，代码逻辑简单
- ✅ **统一告警**：所有告警在同一张表，便于分析

---

## 📝 后续优化建议

### Phase 2 - 性能优化（迁移后1个月）

1. **索引优化**
   ```sql
   -- 分析慢查询
   EXPLAIN SELECT ... FROM ws_batch_execution ...;
   
   -- 添加组合索引
   CREATE INDEX idx_task_batch_active 
   ON ws_batch_execution(task_id, batch_id, is_active);
   ```

2. **分区表**（如果数据量增长快）
   ```sql
   -- 按月分区
   ALTER TABLE monitor_alert_log
   PARTITION BY RANGE (TO_DAYS(create_time)) (
     PARTITION p202501 VALUES LESS THAN (TO_DAYS('2025-02-01')),
     PARTITION p202502 VALUES LESS THAN (TO_DAYS('2025-03-01')),
     ...
   );
   ```

### Phase 3 - 功能增强（迁移后2个月）

1. **配置模板市场**
   - 用户可分享配置模板
   - 一键应用其他用户的配置

2. **任务调度优化**
   - 智能任务自动刷新Token列表
   - 批次动态调整（自动合并/拆分）

3. **告警规则引擎**
   - 支持复杂的告警条件
   - 告警聚合（避免刷屏）

---

## 🤝 团队协作

### 需要参与的角色

| 角色 | 职责 | 工作量 |
|------|------|--------|
| **Backend开发** | 数据迁移脚本、Java代码改造 | 5人天 |
| **Python开发** | 监控脚本适配新表结构 | 3人天 |
| **Frontend开发** | 页面适配（最小改动） | 1人天 |
| **DBA** | SQL审核、数据迁移执行 | 2人天 |
| **运维** | 灰度发布、监控指标 | 3人天 |
| **测试** | 功能测试、性能测试 | 3人天 |

**总计：约 17 人天**

---

## ✅ 检查清单

### 迁移前检查

- [ ] 新表SQL已审核
- [ ] 数据迁移脚本已测试
- [ ] 数据备份已完成
- [ ] 双写代码已开发完成
- [ ] Python兼容性已确认
- [ ] 测试环境已验证通过

### 迁移中检查

- [ ] 数据迁移已完成
- [ ] 数据校验已通过
- [ ] 双写模式已开启
- [ ] 告警数量对比正常
- [ ] 性能指标正常

### 迁移后检查

- [ ] 所有监控任务正常运行
- [ ] 告警通知正常发送
- [ ] 用户无异常反馈
- [ ] 性能有提升
- [ ] 旧表已备份并删除

---

## 📚 参考资料

1. [MySQL大表在线迁移方案](https://dev.mysql.com/doc/)
2. [零停机数据库迁移最佳实践](https://martinfowler.com/articles/zero-downtime-migrations.html)
3. [数据库重构模式](https://www.refactoring-databases.com/)

---

## 📞 联系方式

- **技术负责人**: [你的名字]
- **项目经理**: [PM名字]
- **紧急联系**: [电话/邮箱]

---

**文档状态**: ✅ 已完成设计，待决策是否实施

**决策建议**: 
- ✅ **建议实施** - 长期收益大于短期成本
- ⏰ **最佳时机** - 用户活跃度较低的时段（如周末）
- 🛡️ **风险可控** - 有完整的回滚方案

**最终决策**: [ ] 批准实施 / [ ] 暂缓实施 / [ ] 拒绝实施

---

*最后更新: 2025-11-07*

